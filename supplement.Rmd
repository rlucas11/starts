# Confusion About Between-Person and Within-Person Associations

As noted in the main text, confusion about the interpretation of models like the RI-CLPM likely results from the discussed ambiguities regarding the terms "between-person" and "within-person," along with differences in the ways that different types of multilevel models separate between- and within-person associations. The RI-CLPM separates between-person associations from within-person associations, but it does not do so by relegating all between-person differences to the random intercept [cf. @orth_testing_2021].

As @curran_disaggregation_2011 noted, what is probably the most familiar way to separate between-person associations from within-person associations is the use of person-mean centering. For instance, in the context of multilevel modeling, researchers are often warned that if they are not careful about how they enter variables into the model, what may look like within-person associations (e.g., the "Level-1" effects in repeated-measures data) can actually reflect a mix of between and within. The recommended solution in this context is to person-center the predictor [e.g., @curran_disaggregation_2011; @enders2007centering], where each observation now reflects a deviation from a person's observed mean. When centering this way, the Level-1 part of the model tests whether occasion-specific deviations from a person's mean predict variability in the outcome. 

In their own critique of the RI-CLPM, @ludtke_critique_2021 imply that the RI-CLPM and related models accomplish the separation of between- and within-person associations in the exact same way as the multilevel modeling approach described by @curran_disaggregation_2011[^mlm]. They cautioned that "researchers should be aware that within-person effects are based on person-mean centered (i.e., ipsatized) scores that only capture temporary fluctuations around individual person means" which would be "less appropriate for understanding the potential effects of causes that explain differences between persons" (p. 18). @asendorpf_modeling_2021 echoed this description, stating that models like the RI-CLPM are "similar to using ipsatized scores or person-mean centered scores" (p. 830). Neither clarify, however, that the "person mean" in their description is not the observed person mean calculated from the actual observations (as it would typically be in the traditional multilevel modeling context), but a latent mean that reflects only the variance that is perfectly stable over time. These "means" are---conceptually and empirically---very different things. This also means that what is left after adjusting for these means (the "ipsatized" scores) can also be very different depending on which "mean" is used.

[^mlm]: For discussions about the similarity and differences between the multilevel modeling and structural equation modeling approaches, see @hamaker_fixed_2020 and @falkenstrom_how_2022.

To appreciate this difference, consider the example in Figure \@ref(fig:between). The models shown in this figure represent a single variable, *X*, measured across three occasions. Panel A shows the data-generating process that I used for this example, which reflects a very simple autoregressive model. In this example, the initial variance for *X~1~* was set to 1, and the wave-to-wave stability was set to .5. This simple autoregressive model links between-person differences at Time 1 to between-person differences at Time 2 through a stability coefficient. Note that it would be possible to extend this model to a traditional CLPM by adding an outcome variable at each wave and then testing the lagged paths from the predictor to the outcome and the outcome to the predictor. 

```{r between, echo=FALSE, message=FALSE, warning=FALSE, fig.cap='Different ways of conceptualizing between-person variance.', out.width = "100%"}

knitr::include_graphics("images/betweenExample.png")

```

With these data, it is possible (and meaningful) to consider what each person's mean would be across these three occasions. A simple latent-trait model (like the one shown in Panel B) would capture the variance in these means. Note that in this simple latent-trait model, the variance in each wave is partitioned into variance in the person mean (the variance of the common latent trait, which is .48 in this example) and variance in the wave-specific deviations from that mean (.68, .42, and .64). The components of the model in the blue box could be considered the "within-person" part of this model, as these residuals reflect wave-specific deviations from the person mean. The partitioning of variance in this example is quite similar to the descriptions that @ludtke_critique_2021, @orth_testing_2021, and @asendorpf_modeling_2021 provide for the variance partitioning in the RI-CLPM. 

It is the third panel of this figure, however, that most closely represents (in a univariate setting) what the RI-CLPM and related models actually do. In this panel, the residuals have an autoregressive structure, where the residuals for each wave are predicted from the residuals of the wave prior (exactly as they are in the RI-CLPM). When residuals are structured in this way, they capture between-person variance that is somewhat---but usually not perfectly---stable over time. By structuring the residuals to allow for some wave-to-wave stability, the latent trait now includes only the variance that is *perfectly* stable over this time period. The residuals no longer represent deviations from the person mean, they represent deviations from this *perfectly stable trait*[^kou]. Importantly, although the parts of the model included in the blue box could still be considered the "within-person" part of the model, these structured residuals now link meaningful between-person differences (broadly defined) at Time 1 to between-person differences at Time 2. Indeed, in this specific example, because the data-generating process specifies that there is no perfectly stable variance, these "deviations" are identical to the original variables themselves. The parameter estimates from this model almost perfectly recover the values specified in the simple autoregressive data-generating process[^converge]. 

[^kou]: Thanks to Kou Murayama for discussions that clarified this issue. 
[^converge]: Note that this model fit to data with no stable trait variance will often result in inadmissable solutions because with true latent-trait variance of 0, it is possible to get estimates that are negative, as is the case in the data generated for this example. 

A comparison of the variance estimates across Panels B and C show that the latent trait that links the three observations captures something very different in a simple latent-trait model as compared to a model with structured residuals. However, one could describe either the latent trait from Panel B or the one from Panel C as reflecting the "between-person variance" in these assessments. The latent trait in Panel B captures between-person differences in mean levels of *X* during the observed period of assessment; the latent trait in Panel C captures between-person differences in *a hypothetically perfectly stable* trait. Moreover, one could describe the residuals in either model as reflecting the "within-person" part of the model even though they correspond to conceptually different things. The occasion-specific residuals in Panel C do not reflect deviations from the person mean, they reflect deviations from the perfectly stable trait. 
